{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42y6-4I2l10h"
      },
      "source": [
        "Straing SALES FORECATING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX0IDeeOl5DA"
      },
      "outputs": [],
      "source": [
        "#Import All required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import multiprocessing as mp\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DtwLf8kmLpo"
      },
      "outputs": [],
      "source": [
        "#Reading all the Data using pandas\n",
        "df=pd.read_csv('calendar.csv')\n",
        "df1=pd.read_csv('sales_train_validation.csv') #this is used for training\n",
        "df2=pd.read_csv('sell_prices.csv')\n",
        "df3=pd.read_csv('sales_train_evaluation.csv') # this is used for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "V-DdTPX6L2s7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "AB1uta3SmlN4",
        "outputId": "91cc4820-609d-470f-f913-41d7cd06ee0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
              "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
              "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
              "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
              "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
              "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
              "\n",
              "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
              "0          NaN          NaN          NaN        0        0        0  \n",
              "1          NaN          NaN          NaN        0        0        0  \n",
              "2          NaN          NaN          NaN        0        0        0  \n",
              "3          NaN          NaN          NaN        1        1        0  \n",
              "4          NaN          NaN          NaN        1        0        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f46bdc85-84bb-4bb4-874c-485a3aa21c2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f46bdc85-84bb-4bb4-874c-485a3aa21c2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f46bdc85-84bb-4bb4-874c-485a3aa21c2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f46bdc85-84bb-4bb4-874c-485a3aa21c2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hXpmBwJEmloP",
        "outputId": "aab0bac3-e7bc-494b-b3f8-d63c02c0d183"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              id        item_id    dept_id   cat_id store_id  \\\n",
              "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
              "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
              "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
              "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
              "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
              "\n",
              "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
              "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
              "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
              "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
              "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
              "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
              "\n",
              "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
              "0       1       3       0       1       1  \n",
              "1       1       0       0       0       0  \n",
              "2       1       0       1       1       1  \n",
              "3       0       1       3       7       2  \n",
              "4       1       2       2       2       4  \n",
              "\n",
              "[5 rows x 1919 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bc773dd-8e3f-41e3-b942-8817142832e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1919 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc773dd-8e3f-41e3-b942-8817142832e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bc773dd-8e3f-41e3-b942-8817142832e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bc773dd-8e3f-41e3-b942-8817142832e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw2CqTMomsdK"
      },
      "source": [
        "OBSERVATION\n",
        "\n",
        "We have sales for 1941 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "xrtARxiEmpX4",
        "outputId": "441c2411-0080-4a5e-a6fc-c62421bfd1a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              id        item_id    dept_id   cat_id store_id  \\\n",
              "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
              "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
              "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
              "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
              "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
              "\n",
              "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
              "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
              "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
              "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
              "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
              "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
              "\n",
              "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
              "0       0       3       3       0       1  \n",
              "1       0       0       0       0       0  \n",
              "2       0       2       3       0       1  \n",
              "3       1       3       0       2       6  \n",
              "4       0       0       2       1       0  \n",
              "\n",
              "[5 rows x 1947 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef6815eb-a43a-4009-aadb-9f3b836e4e26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1947 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef6815eb-a43a-4009-aadb-9f3b836e4e26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef6815eb-a43a-4009-aadb-9f3b836e4e26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef6815eb-a43a-4009-aadb-9f3b836e4e26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0VR9cIhmusc"
      },
      "source": [
        "OBSERVATION\n",
        "\n",
        "Here we have data for 1947 data. we will use this dataframe for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AjFi89_1mwuY",
        "outputId": "17183d68-dd00-49ac-c9c7-d5fe21412204"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  store_id        item_id  wm_yr_wk  sell_price\n",
              "0     CA_1  HOBBIES_1_001   11325.0        9.58\n",
              "1     CA_1  HOBBIES_1_001   11326.0        9.58\n",
              "2     CA_1  HOBBIES_1_001   11327.0        8.26\n",
              "3     CA_1  HOBBIES_1_001   11328.0        8.26\n",
              "4     CA_1  HOBBIES_1_001   11329.0        8.26"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78015efc-0a4d-4a40-9206-f013597926c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>sell_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11325.0</td>\n",
              "      <td>9.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11326.0</td>\n",
              "      <td>9.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11327.0</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11328.0</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>11329.0</td>\n",
              "      <td>8.26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78015efc-0a4d-4a40-9206-f013597926c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78015efc-0a4d-4a40-9206-f013597926c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78015efc-0a4d-4a40-9206-f013597926c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InwikEo7myGP",
        "outputId": "44866525-3641-45c1-8ca1-24b6c63efc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of calender.csv (1969, 14)\n",
            "Shape of sales train validation.csv (30490, 1919)\n",
            "Shape of sell_price.csv (5100190, 4)\n",
            "Shape of sales train evaluation.csv (30490, 1947)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of calender.csv\",df.shape)\n",
        "print(\"Shape of sales train validation.csv\",df1.shape)\n",
        "print(\"Shape of sell_price.csv\",df2.shape)\n",
        "print(\"Shape of sales train evaluation.csv\",df3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W39T0JxWmziI"
      },
      "outputs": [],
      "source": [
        "#Clearly in calender.csv we have many entries which contain NaN in event_type_1,event_type_2,event_name_1 & enent_name_2\n",
        "#I have replaced all those entries with no_event\n",
        "df=df.fillna(value='no_event')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "NGcByAFNm0rn",
        "outputId": "55338526-5ebf-4ef1-d636-b8e78b6465b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
              "0  2011-01-29     11101   Saturday     1      1  2011  d_1     no_event   \n",
              "1  2011-01-30     11101     Sunday     2      1  2011  d_2     no_event   \n",
              "2  2011-01-31     11101     Monday     3      1  2011  d_3     no_event   \n",
              "3  2011-02-01     11101    Tuesday     4      2  2011  d_4     no_event   \n",
              "4  2011-02-02     11101  Wednesday     5      2  2011  d_5     no_event   \n",
              "\n",
              "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
              "0     no_event     no_event     no_event        0        0        0  \n",
              "1     no_event     no_event     no_event        0        0        0  \n",
              "2     no_event     no_event     no_event        0        0        0  \n",
              "3     no_event     no_event     no_event        1        1        0  \n",
              "4     no_event     no_event     no_event        1        0        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dacdd1d-9501-42a4-8138-5728f4d83243\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_1</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_2</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>Monday</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_3</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_4</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>d_5</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>no_event</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dacdd1d-9501-42a4-8138-5728f4d83243')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dacdd1d-9501-42a4-8138-5728f4d83243 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dacdd1d-9501-42a4-8138-5728f4d83243');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VqngSoPm39x"
      },
      "source": [
        "Preparing Data in Form one of Single DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY9qdoohm7aP"
      },
      "outputs": [],
      "source": [
        "# https://www.geeksforgeeks.org/python-pandas-melt/#:~:text=melt()%20function%20is%20useful,identifier%20columns%2C%20variable%20and%20value.\n",
        "# Since we need to have days as particular columns I have modified train_evaluation.csv and assigned changed structure of it\n",
        "# I have created d and sales which contains sales for that day \n",
        "# This Increases size of csv file drastically\n",
        "\n",
        "l=[]\n",
        "for i in range(1,1914):\n",
        "  l.append(\"d_\"+str(i))\n",
        "df_final=pd.melt(df1,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
        "                 value_vars=l,var_name=\"d\",value_name=\"sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgWZ7bjLm863"
      },
      "outputs": [],
      "source": [
        "#here I am taking only last 28 data days of test bcz eariler values are same as for train\n",
        "l=[]\n",
        "for i in range(1914,1942):\n",
        "  l.append(\"d_\"+str(i))\n",
        "df_final_test=pd.melt(df3,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
        "                 value_vars=l,var_name=\"d\",value_name=\"sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxkPXQyZm-Gn"
      },
      "outputs": [],
      "source": [
        "for i in range(1942,1970):\n",
        "    df3['d_'+str(i)]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaYcA3b4m_gc"
      },
      "outputs": [],
      "source": [
        "#Also create future data to be used for futures sales data\n",
        "l=[]\n",
        "for i in range(1942,1970):\n",
        "    l.append(\"d_\"+str(i))\n",
        "df_future_data=pd.melt(df3,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
        "                 value_vars=l,var_name=\"d\",value_name=\"sales\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgP47mvEnCDn"
      },
      "outputs": [],
      "source": [
        "#Now we merge all These 3 dataframes to get final csv file train\n",
        "data=df_final.merge(df,on='d',copy=False)# combine calender.csv and modified trainevaluation.csv on feature 'd'\n",
        "data=data.merge(df2,on=[\"store_id\", \"item_id\", \"wm_yr_wk\"],copy=False) # combine new dataframe with sell_price.csv usnig features \"store_id\", \"item_id\", \"wm_yr_wk\"\n",
        "# I am storing this final dataframe to final_dataframe.csv\n",
        "data.to_csv('final_dataframe.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3FhDd69nDiB"
      },
      "outputs": [],
      "source": [
        "#Now we merge all These 3 dataframes to get final csv file test\n",
        "data_test=df_final_test.merge(df,on='d',copy=False)# combine calender.csv and modified trainevaluation.csv on feature 'd'\n",
        "data_test=data_test.merge(df2,on=[\"store_id\", \"item_id\", \"wm_yr_wk\"],copy=False) # combine new dataframe with sell_price.csv usnig features \"store_id\", \"item_id\", \"wm_yr_wk\"\n",
        "# I am storing this final dataframe to final_dataframe.csv\n",
        "data_test.to_csv('final_dataframe_test.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_-nfYr_nJ82"
      },
      "outputs": [],
      "source": [
        "#Now we merge all These 3 dataframes to get final csv file future data\n",
        "data_future=df_future_data.merge(df,on='d',copy=False)# combine calender.csv and modified trainevaluation.csv on feature 'd'\n",
        "data_future=data_future.merge(df2,on=[\"store_id\", \"item_id\", \"wm_yr_wk\"],copy=False) # combine new dataframe with sell_price.csv usnig features \"store_id\", \"item_id\", \"wm_yr_wk\"\n",
        "# I am storing this final dataframe to final_future_data.csv\n",
        "data_future.fillna('no_event',inplace=True)\n",
        "data_future.to_csv('final_future_data.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWzRC96LnLZn"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of final dataframe train is=\",data.shape)\n",
        "print(\"Shape of final dataframe test is=\",data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I03ObybanN_f"
      },
      "outputs": [],
      "source": [
        "#reading up complete dataframe\n",
        "data=pd.read_csv('final_dataframe.csv')\n",
        "data_test=pd.read_csv('final_dataframe_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd5_GxR4nPgm"
      },
      "source": [
        "Exploring various properties of DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmJep0JmnWpH"
      },
      "outputs": [],
      "source": [
        "print(\"Head rows of Final DataFrame train\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea8KclqFnYFX"
      },
      "outputs": [],
      "source": [
        "print(\"Colums present in dataFrame are\",data.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EJWNjuvnZJv"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Complete information about data Frame is:-\\n\")\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQG1ddHlndI5"
      },
      "outputs": [],
      "source": [
        "print(\"There are these unique stores in this data=\",data['store_id'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOD09KyNnenG"
      },
      "outputs": [],
      "source": [
        "print(\"There are these sates in data=\",data['state_id'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLrQDM7Jni3h"
      },
      "outputs": [],
      "source": [
        "print(\"Unique values of wday features=\",data['wday'].unique())\n",
        "print(\"Unique values of weekday features=\",data['weekday'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ3_iUCtnnCY"
      },
      "outputs": [],
      "source": [
        "print(\"years for which I have this sales data=\",data['year'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUFztRHTpfwp"
      },
      "outputs": [],
      "source": [
        "print(\"Months in year 2016 for which we have data\",data[data['year']==2016]['month'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoKe-OHUpjzF"
      },
      "source": [
        "Note:-Here we have data for year 2016 for only 5 months(5th month for test data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H1Idv_1plOI"
      },
      "source": [
        "**Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOswgIEgpqke"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UDwBXROpkTN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import multiprocessing as mp\n",
        "import gc\n",
        "import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import calendar\n",
        "from scipy.sparse import csr_matrix,hstack\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from lightgbm import LGBMRegressor\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8yYHCP3p5n2"
      },
      "outputs": [],
      "source": [
        "#Reading up the dataframes\n",
        "train=pd.read_csv('final_dataframe.csv')\n",
        "test=pd.read_csv('final_dataframe_test.csv')\n",
        "final_test=pd.read_csv('final_future_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR_X9zslp7AA"
      },
      "source": [
        "Reducing Memory by converting all categorical varaibles to integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnEEt6KJp8nu"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['item_id']=lbl.fit_transform(train['item_id'])\n",
        "test['item_id']=lbl.transform(test['item_id'])\n",
        "final_test['item_id']=lbl.transform(final_test['item_id'])\n",
        "pickle.dump(lbl,open('label_encoder_item_id.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtvb6qDwp_Yf"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['dept_id']=lbl.fit_transform(train['dept_id'])\n",
        "test['dept_id']=lbl.transform(test['dept_id'])\n",
        "final_test['dept_id']=lbl.transform(final_test['dept_id'])\n",
        "pickle.dump(lbl,open('label_encoder_dept_id.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YFwKCc_qAsL"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['cat_id']=lbl.fit_transform(train['cat_id'])\n",
        "test['cat_id']=lbl.transform(test['cat_id'])\n",
        "final_test['cat_id']=lbl.transform(final_test['cat_id'])\n",
        "pickle.dump(lbl,open('label_encoder_cat_id.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzaUMnypqCDG"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['store_id']=lbl.fit_transform(train['store_id'])\n",
        "test['store_id']=lbl.transform(test['store_id'])\n",
        "final_test['store_id']=lbl.transform(final_test['store_id'])\n",
        "pickle.dump(lbl,open('label_encoder_store_id.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwoYlQliqDuR"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['state_id']=lbl.fit_transform(train['state_id'])\n",
        "test['state_id']=lbl.transform(test['state_id'])\n",
        "final_test['state_id']=lbl.transform(final_test['state_id'])\n",
        "pickle.dump(lbl,open('label_encoder_state_id.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX5ZKzuRqE6P"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['event_name_1']=lbl.fit_transform(train['event_name_1'])\n",
        "test['event_name_1']=lbl.transform(test['event_name_1'])\n",
        "final_test['event_name_1']=lbl.transform(final_test['event_name_1'])\n",
        "pickle.dump(lbl,open('label_encoder_event_name_1.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FksmhH2JqGVO"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['event_name_2']=lbl.fit_transform(train['event_name_2'])\n",
        "test['event_name_2']=lbl.transform(test['event_name_2'])\n",
        "final_test['event_name_2']=lbl.transform(final_test['event_name_2'])\n",
        "pickle.dump(lbl,open('label_encoder_event_name_2.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twYQIjPAqHlW"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['event_type_1']=lbl.fit_transform(train['event_type_1'])\n",
        "test['event_type_1']=lbl.transform(test['event_type_1'])\n",
        "final_test['event_type_1']=lbl.transform(final_test['event_type_1'])\n",
        "pickle.dump(lbl,open('label_encoder_event_type_1.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ty7i0NXqIl2"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['event_type_2']=lbl.fit_transform(train['event_type_2'])\n",
        "test['event_type_2']=lbl.transform(test['event_type_2'])\n",
        "final_test['event_type_2']=lbl.transform(final_test['event_type_2'])\n",
        "pickle.dump(lbl,open('label_encoder_event_type_2.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-l1jlCgqJju"
      },
      "outputs": [],
      "source": [
        "lbl=LabelEncoder()\n",
        "train['year']=lbl.fit_transform(train['year'])\n",
        "test['year']=lbl.transform(test['year'])\n",
        "final_test['year']=lbl.transform(final_test['year'])\n",
        "pickle.dump(lbl,open('label_encoder_year.sav','wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_srpsLHqNxQ"
      },
      "source": [
        "Removing Unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEO3dV3rqVPG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Converting snap_CA,snap_WI,snap_TX into one feature named snap\n",
        "train.loc[train['state_id'] == 'CA', 'snap'] = train.loc[train['state_id'] == 'CA']['snap_CA']\n",
        "train.loc[train['state_id'] == 'TX', 'snap'] = train.loc[train['state_id'] == 'TX']['snap_TX']\n",
        "train.loc[train['state_id'] == 'WI', 'snap'] = train.loc[train['state_id'] == 'WI']['snap_WI']\n",
        "train.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "test.loc[test['state_id'] == 'CA', 'snap'] = test.loc[test['state_id'] == 'CA']['snap_CA']\n",
        "test.loc[test['state_id'] == 'TX', 'snap'] = test.loc[test['state_id'] == 'TX']['snap_TX']\n",
        "test.loc[test['state_id'] == 'WI', 'snap'] = test.loc[test['state_id'] == 'WI']['snap_WI']\n",
        "test.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)\n",
        "\n",
        "final_test.loc[final_test['state_id'] == 'CA', 'snap'] = final_test.loc[final_test['state_id'] == 'CA']['snap_CA']\n",
        "final_test.loc[final_test['state_id'] == 'TX', 'snap'] = final_test.loc[final_test['state_id'] == 'TX']['snap_TX']\n",
        "final_test.loc[final_test['state_id'] == 'WI', 'snap'] = final_test.loc[final_test['state_id'] == 'WI']['snap_WI']\n",
        "final_test.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kqsXDvVqZvV"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Weekday as wday are similar features so we remove it\n",
        "#no use of  wm_yr_wk feature\n",
        "train.drop('weekday',axis=1,inplace=True)\n",
        "train.drop('wm_yr_wk',axis=1,inplace=True)\n",
        " \n",
        "test.drop('weekday',axis=1,inplace=True)\n",
        "test.drop('wm_yr_wk',axis=1,inplace=True)\n",
        "\n",
        "final_test.drop('weekday',axis=1,inplace=True)\n",
        "final_test.drop('wm_yr_wk',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX_UeheLqbvo"
      },
      "source": [
        "1.Date Related Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6W9K21YqcvG"
      },
      "source": [
        "1.Week Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzwFm46VqdcW"
      },
      "outputs": [],
      "source": [
        "#Reference https://stackoverflow.com/questions/2600775/how-to-get-week-number-in-python/32638267#:~:text=()%5B1%5D%2024-,datetime.,for%20the%20given%20date%20instance.&text=You%20can%20get%20the%20week%20number%20directly%20from%20datetime%20as%20string.\n",
        "def get_week_number(x):\n",
        "    \"\"\"This Function is used to get weeknumber of particular date\"\"\"\n",
        "    date=calendar.datetime.date.fromisoformat(x)\n",
        "    return date.isocalendar()[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4OLPGIiqfq4"
      },
      "outputs": [],
      "source": [
        "train['week_number']=train['date'].apply(lambda x:get_week_number(x))\n",
        "test['week_number']=test['date'].apply(lambda x:get_week_number(x))\n",
        "final_test['week_number']=final_test['date'].apply(lambda x:get_week_number(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sugrc9Hqhzs"
      },
      "source": [
        "\n",
        "2.Season"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcqvg8a9qjSZ"
      },
      "outputs": [],
      "source": [
        "#https://www.universaltraveller.com.au/destinations/los-angeles/weather\n",
        "def get_season(x):\n",
        "    \"\"\"This function is used to get season in US according to various months\"\"\"\n",
        "    if x in [12,1,2]:\n",
        "        return 0      #\"Winter\"\n",
        "    elif x in [3,4,5]:\n",
        "        return 1   #\"Spring\"\n",
        "    elif x in [6,7,8]:\n",
        "        return 2   #\"Summer\"\n",
        "    else:\n",
        "        return 3   #\"Autumn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VqQKC5oqld3"
      },
      "outputs": [],
      "source": [
        "train['season']=train['month'].apply(lambda x:get_season(x))\n",
        "test['season']=test['month'].apply(lambda x:get_season(x))\n",
        "final_test['season']=final_test['month'].apply(lambda x:get_season(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWdQgjXEq2pf"
      },
      "source": [
        "3.Quater Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFdCSHweq3z-"
      },
      "outputs": [],
      "source": [
        "def check_if_quater_begin(x):\n",
        "    \"\"\"This is used to check if day is begining of quater\"\"\"\n",
        "    day=calendar.datetime.date.fromisoformat(x).day\n",
        "    month=calendar.datetime.date.fromisoformat(x).month\n",
        "    return 1 if (day==1 and (month in [1,4,7,9])) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb4w6L7dq5B2"
      },
      "outputs": [],
      "source": [
        "train['quater_start']=train['date'].apply(lambda x:check_if_quater_begin(x))\n",
        "test['quater_start']=test['date'].apply(lambda x:check_if_quater_begin(x))\n",
        "final_test['quater_start']=final_test['date'].apply(lambda x:check_if_quater_begin(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey6gYHGsq6hI"
      },
      "source": [
        "4.Quater End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNhN-sT0q7qX"
      },
      "outputs": [],
      "source": [
        "#Reference https://www.lawinsider.com/dictionary/quarter-end\n",
        "def check_if_quater_end(x):\n",
        "    \"\"\"This is used to check if day is end of quater\"\"\"\n",
        "    day=calendar.datetime.date.fromisoformat(x).day\n",
        "    month=calendar.datetime.date.fromisoformat(x).month\n",
        "    if (day==31 and month==3) or (day==30 and month==6) or (day==30 and month==9) or (day==31 and month==12):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bgSF19Eq-BO"
      },
      "outputs": [],
      "source": [
        "train['quater_end']=train['date'].apply(lambda x:check_if_quater_end(x))\n",
        "test['quater_end']=test['date'].apply(lambda x:check_if_quater_end(x))\n",
        "final_test['quater_end']=final_test['date'].apply(lambda x:check_if_quater_end(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjjvQ37MrHDO"
      },
      "source": [
        "5.Month Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khrPc1hgrC7F"
      },
      "outputs": [],
      "source": [
        "def month_start(x):\n",
        "    \"\"\"This is used to check if day is begining of month\"\"\"\n",
        "    day=calendar.datetime.date.fromisoformat(x).day\n",
        "    return 1 if day==1 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KEQi7EzrEaI"
      },
      "outputs": [],
      "source": [
        "train['month_start']=train['date'].apply(lambda x:month_start(x))\n",
        "test['month_start']=test['date'].apply(lambda x:month_start(x))\n",
        "final_test['month_start']=final_test['date'].apply(lambda x:month_start(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Month End"
      ],
      "metadata": {
        "id": "CiaVyEyMJ0YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def month_end(x):\n",
        "    \"\"\"This is used to check if day is end of month\"\"\"\n",
        "    day=calendar.datetime.date.fromisoformat(x).day\n",
        "    month=calendar.datetime.date.fromisoformat(x).month\n",
        "    year=calendar.datetime.date.fromisoformat(x).year\n",
        "    leap_yr=(year%4==0) # to check if it is a leap year\n",
        "    val=(day==31 and month==1) or (day==29 if leap_yr else day==28) or (day==31 and month==3) or (day==30 and month==4) or\\\n",
        "        (day==31 and month==5) or (day==30 and month==6) or (day==31 and month==7) or (day==31 and month==8) or\\\n",
        "        (day==30 and month==9) or (day==31 and month==10) or (day==30 and month==11) or (day==31 and month==12)\n",
        "    return 1 if val else 0"
      ],
      "metadata": {
        "id": "gnTTJ1wYJ1Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['month_end']=train['date'].apply(lambda x:month_end(x))\n",
        "test['month_end']=test['date'].apply(lambda x:month_end(x))\n",
        "final_test['month_end']=final_test['date'].apply(lambda x:month_end(x))"
      ],
      "metadata": {
        "id": "cWrj32n3J8xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Year Start"
      ],
      "metadata": {
        "id": "_RJ7wmYoJ_j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def year_start(x):\n",
        "    \"\"\"This is used to check if day is begining of year\"\"\"\n",
        "    day=calendar.datetime.date.fromisoformat(x).day\n",
        "    month=calendar.datetime.date.fromisoformat(x).month\n",
        "    return 1 if (day==1 and month==1) else 0"
      ],
      "metadata": {
        "id": "NtB-1slpKAKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['year_start']=train['date'].apply(lambda x:year_start(x))\n",
        "test['year_start']=test['date'].apply(lambda x:year_start(x))\n",
        "final_test['year_start']=final_test['date'].apply(lambda x:year_start(x))"
      ],
      "metadata": {
        "id": "_LK2jKoWKBpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8.Year End"
      ],
      "metadata": {
        "id": "Hz5t2Au8KEVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def year_end(x):\n",
        "    \"\"\"This is used to check if day is end of year\"\"\"\n",
        "    day=calendar.datetime.date.fromisoformat(x).day\n",
        "    month=calendar.datetime.date.fromisoformat(x).month\n",
        "    return 1 if (day==31 and month==12) else 0"
      ],
      "metadata": {
        "id": "FpyGfUFpKF5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['year_end']=train['date'].apply(lambda x:year_end(x))\n",
        "test['year_end']=test['date'].apply(lambda x:year_end(x))\n",
        "final_test['year_end']=final_test['date'].apply(lambda x:year_end(x))"
      ],
      "metadata": {
        "id": "WOzZ1YynKHVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking Last 28 days from train as CrossValidation so that it can be used while Modeling"
      ],
      "metadata": {
        "id": "VTIY2j97KKGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross Validation data will be used for hyperparameter tuning\n",
        "cv=train[train['date']>='2016-03-28']\n",
        "train=train[train['date']<'2016-03-28']"
      ],
      "metadata": {
        "id": "o-douGX7KL2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Series Related Features"
      ],
      "metadata": {
        "id": "mFtjCFh0KNYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Firstly we will create these Direct features for train  and CV test and final test data\n",
        "# Code to create one large data for all days\n",
        "gc.collect()\n",
        "tt=pd.concat([train,cv,test,final_test])\n",
        "tt.sort_values(['id','date'],inplace=True)\n",
        "df=tt.pivot_table(index=['item_id','store_id'],columns='date',values='sales')\n",
        "df.fillna(0,inplace=True)"
      ],
      "metadata": {
        "id": "DjkRESTPKJAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Rolling mean and Rolling Standard Deviation"
      ],
      "metadata": {
        "id": "YYiD8arMKQlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#this code snippet is used to calculate rolling mean and rolling std of sales data with shift of 30 days \n",
        "# Here we are taking 28 days shift so as to avoid Data Leakage Problem\n",
        "for aggregate in ['mean','std']:\n",
        "    for shif in [30]:\n",
        "        for r in [7,14,30,60,360]:\n",
        "            roll=df.rolling(r,axis=1).agg(aggregate).shift(shif)\n",
        "            dates=roll.columns\n",
        "            name=\"roll_\"+str(r)+\"_shift_\"+str(shif)+\"_\"+aggregate\n",
        "            roll=roll.astype('float16')\n",
        "            roll.reset_index(level=[0,1],inplace=True)\n",
        "            roll=pd.melt(roll,id_vars=['item_id','store_id'],value_vars=dates,var_name='date',value_name=name)\n",
        "            roll.fillna(-1,inplace=True)\n",
        "            train=train.merge(roll,on=['item_id','store_id','date'])\n",
        "            cv=cv.merge(roll,on=['item_id','store_id','date'])\n",
        "            final_test=final_test.merge(roll,on=['item_id','store_id','date'])\n",
        "            test=test.merge(roll,on=['item_id','store_id','date'])\n",
        "            print(\"Feature created named :=\",name)\n",
        "            del roll\n",
        "            gc.collect()"
      ],
      "metadata": {
        "id": "Eop5XUPwKPdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Exponential Weighted Average"
      ],
      "metadata": {
        "id": "rSu7gnHNKZZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding  Exponential weighted average with shift of 28 days\n",
        "# Shift of 28 days is used to prevent data leakage Problem\n",
        "roll=df.shift(28,axis=1).ewm(alpha=0.99,axis=1,adjust=False).mean()\n",
        "dates=roll.columns\n",
        "roll=roll.astype('float16')\n",
        "roll.reset_index(level=[0,1],inplace=True)\n",
        "roll=pd.melt(roll,id_vars=['item_id','store_id'],value_vars=dates,var_name='date',value_name='direct_ewm')\n",
        "roll.fillna(-1,inplace=True)\n",
        "train=train.merge(roll,on=['item_id','store_id','date'])\n",
        "cv=cv.merge(roll,on=['item_id','store_id','date'])\n",
        "test=test.merge(roll,on=['item_id','store_id','date'])\n",
        "final_test=final_test.merge(roll,on=['item_id','store_id','date'])\n",
        "print(\"Direct Feature created ewa window of size\")"
      ],
      "metadata": {
        "id": "BZntwrBsKbaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downcast the datasets"
      ],
      "metadata": {
        "id": "dgQeE-KqAsla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def downcast(df):\n",
        "    cols = df.dtypes.index.tolist()\n",
        "    types = df.dtypes.values.tolist()\n",
        "    for i,t in enumerate(types):\n",
        "        if 'int' in str(t):\n",
        "            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
        "            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
        "            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
        "            else:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
        "        elif 'float' in str(t):\n",
        "            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.float16)\n",
        "            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
        "            else:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
        "        elif t == np.object:\n",
        "            if cols[i] == 'date':\n",
        "                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n",
        "            else:\n",
        "                df[cols[i]] = df[cols[i]].astype('category')\n",
        "    return df  "
      ],
      "metadata": {
        "id": "BF8NMKBfA5B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge the datasets"
      ],
      "metadata": {
        "id": "2N-QjKkwA-i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()\n",
        "\n",
        "df = pd.merge(df, calendar, on='d', how='left')\n",
        "df = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') "
      ],
      "metadata": {
        "id": "t7bbzUb7A-xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Lag Features"
      ],
      "metadata": {
        "id": "5R0S3r2WKdIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Now we will also calculate lag features with lag of 28,35,42,49,56,63,70,77,84,91,96 days\n",
        "for lag in range(28,100,7):\n",
        "    i='direct_lag_'+str(lag)\n",
        "    lag_i=df.shift(lag,axis=1)\n",
        "    dates=lag_i.columns\n",
        "    lag_i.reset_index(level=[0,1],inplace=True)\n",
        "    lag_i=pd.melt(lag_i,id_vars=['item_id','store_id'],value_vars=dates,var_name='date',value_name=i)\n",
        "    lag_i.fillna(-1,inplace=True)\n",
        "    lag_i[i]=lag_i[i].astype('int16')\n",
        "    train=train.merge(lag_i,on=['item_id','store_id','date'])\n",
        "    cv=cv.merge(lag_i,on=['item_id','store_id','date'])\n",
        "    test=test.merge(lag_i,on=['item_id','store_id','date'])\n",
        "    final_test=final_test.merge(lag_i,on=['item_id','store_id','date'])\n",
        "    print(\"Feature created for lag\",lag)\n",
        "    del lag_i\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "SWzX0Ye0Kdr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving All features Created"
      ],
      "metadata": {
        "id": "Btv5-aX4Kgyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train.to_csv('train1.csv',index=False)\n",
        "cv.to_csv('cv1.csv',index=False)\n",
        "test.to_csv('test1.csv',index=False)\n",
        "final_test.to_csv('final_test1.csv',index=False)"
      ],
      "metadata": {
        "id": "34mAgVmhKimJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales Forecasting--Modeling"
      ],
      "metadata": {
        "id": "nT2w38o9K-Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import dask.dataframe as dk\n",
        "import calendar\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler,Normalizer\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.sparse import csr_matrix,hstack\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from catboost import CatBoostRegressor\n",
        "import catboost as cat\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "import pickle"
      ],
      "metadata": {
        "id": "WOPpV0ilK9PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this snippet of code is used to reduce memory consumption by dataframe\n",
        "dtype={'id'       :     'object', \n",
        "    'item_id'     :  'int64', \n",
        "    'dept_id'     :  'int8', \n",
        "    'cat_id'      :  'int8', \n",
        "    'store_id'    :  'int8', \n",
        "    'state_id'    :  'int8', \n",
        "    'd'           :  'object', \n",
        "    'sales'       :  'int16',  \n",
        "    'date'        : 'object', \n",
        "   'wday'        :  'int8',  \n",
        "   'month'       :  'int8',  \n",
        "   'year'        :  'int16',  \n",
        "   'event_name_1' : 'int8', \n",
        "   'event_type_1' : 'int8', \n",
        "   'event_name_2' : 'int8', \n",
        "   'event_type_2' : 'int8', \n",
        "    'snap':'int8',\n",
        "  'sell_price'   : 'float16',\n",
        "       'price_change':'float16',\n",
        "   'week_number'  : 'int8',  \n",
        "   'season'       : 'object', \n",
        "   'quater_start' : 'int8',  \n",
        "   'quater_end'   : 'int8',  \n",
        "   'month_start'  : 'int8',  \n",
        "   'month_end'    : 'int8',  \n",
        "   'year_start'   : 'int8',  \n",
        "   'year_end'     : 'int8',  \n",
        "   'group'        : 'int8',  \n",
        "   'no_events'    : 'object', \n",
        "   'holiday'      : 'object',\n",
        "    'week_number':'int8',\n",
        "       'season':'int8',\n",
        "       'quater_start':'int8',\n",
        "       'quater_end':'int8',\n",
        "       'month_start':'int8',\n",
        "       'month_end':'int8',\n",
        "       'year_start':'int8',\n",
        "       'year_end':'int8',\n",
        "       'roll_7_shift_28_mean':'float16',\n",
        "       'roll_14_shift_28_mean':'float16',\n",
        "       'roll_30_shift_28_mean':'float16',\n",
        "       'roll_60_shift_28_mean':'float16',\n",
        "       'roll_360_shift_28_mean':'float16',\n",
        "       'roll_7_shift_28_std':'float16',\n",
        "       'roll_14_shift_28_std':'float16',\n",
        "       'roll_30_shift_28_std':'float16',\n",
        "       'roll_60_shift_28_std':'float16',\n",
        "       'roll_360_shift_28_std':'float16',\n",
        "       'direct_ewm':'float16',\n",
        "       'direct_lag_28':'int16',\n",
        "       'direct_lag_35':'int16',\n",
        "       'direct_lag_42':'int16',\n",
        "       'direct_lag_49':'int16',\n",
        "       'direct_lag_56':'int16',\n",
        "       'direct_lag_63':'int16',\n",
        "       'direct_lag_70':'int16',\n",
        "       'direct_lag_77':'int16',\n",
        "       'direct_lag_84':'int16',\n",
        "       'direct_lag_91':'int16',\n",
        "       'direct_lag_98':'int16',\n",
        "       'min_price':'float16',\n",
        "       'max_price':'float16',\n",
        "       'mean_price':'float16',\n",
        "       'std_price':'float16',\n",
        "       'price_norm_1':'float16',\n",
        "       'price_norm_2':'float16',\n",
        "       'price_norm_3':'float16',\n",
        "      }"
      ],
      "metadata": {
        "id": "iBdZqfkkLACz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('train1.csv',dtype=dtype)\n",
        "cv=pd.read_csv('cv1.csv',dtype=dtype)\n",
        "test=pd.read_csv('test1.csv',dtype=dtype)\n",
        "final_test=pd.read_csv('final_test1.csv',dtype=dtype)"
      ],
      "metadata": {
        "id": "RXMC1tPlLBrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metric Calculation Functions"
      ],
      "metadata": {
        "id": "lgObJ-ftLE5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def caluclate_WRMSSE(actual,predicted,train,weights,h,n):\n",
        "    '''This function is used to calculate RMSSE'''\n",
        "    num=((actual-predicted)**2).sum(axis=1)/h\n",
        "    denom=(train[:,1:]-train[:,:-1])**2\n",
        "    denom=denom.sum(axis=1)/(n-1)\n",
        "    return (num/denom)**0.5"
      ],
      "metadata": {
        "id": "6B6M15ZILDAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_performances(model,train,cv,test,X_cv,X_test):\n",
        "    '''This Function is used to get WRMSSE that is used in this Case Study as a Metric For CV and Test Data'''\n",
        "    #For CV Data\n",
        "    cv['prices']=cv['sales']*cv['sell_price']\n",
        "    total_sales=cv.groupby('id').sum()\n",
        "    total=sum(total_sales['sales'])\n",
        "    weight={}\n",
        "    for i in total_sales.index:\n",
        "        weight[i]=total_sales.loc[i]['sales']/total\n",
        "    train1=pd.concat([train,cv])\n",
        "    train1.sort_values(['id','date'],inplace=True)\n",
        "    train1.fillna(0,inplace=True)\n",
        "    df=train1.pivot_table(index=['id','state_id','store_id','cat_id','dept_id','item_id'],columns='d',values='sales')\n",
        "    df.reset_index(level=[0,1,2,3,4,5],inplace=True)\n",
        "    df.fillna(0,inplace=True)\n",
        "    del train1\n",
        "    import gc\n",
        "    cv['pred_sales']=model.predict(X_cv)\n",
        "    df1=cv.pivot_table(index=['id'],columns='d',values='pred_sales')\n",
        "    dic={}\n",
        "    for j,i in enumerate(range(1886,1914)):\n",
        "        dic['d_'+str(i)]='F'+str(j+1)\n",
        "    df1=df1.rename(columns=dic) \n",
        "    df1.reset_index(level=[0],inplace=True)\n",
        "    dd=df.merge(df1,on='id')\n",
        "    dd['weight']=dd['id'].apply(lambda x:weight[x])\n",
        "    l=['d_'+str(i) for i in range(1,1914)]\n",
        "    l1=['F'+str(i) for i in range(1,29)]\n",
        "    agg_level={2:['state_id'],3:['store_id'],4:['cat_id'],5:['dept_id'],6:['state_id','cat_id'],\\\n",
        "           7:['state_id','dept_id'],8:['store_id','cat_id'],9:['store_id','dept_id'],10:['item_id'],11:['item_id','state_id']}\n",
        "    agg=pd.DataFrame(dd[l+l1].sum()).transpose()\n",
        "    agg['weight']=1/12\n",
        "    agg['level']=1\n",
        "    col=agg.columns\n",
        "    for level in agg_level:\n",
        "        temp_df=dd.groupby(by=agg_level[level]).sum().reset_index(drop=True)\n",
        "        temp_df['weight']/=12\n",
        "        temp_df['level']=level\n",
        "        agg=agg.append(temp_df[col])\n",
        "    dd['weight']/=12\n",
        "    dd['level']=12    \n",
        "    agg=agg.append(dd[col])\n",
        "    actual=agg[['d_1886', 'd_1887', 'd_1888', 'd_1889', 'd_1890', 'd_1891', 'd_1892',\n",
        "       'd_1893', 'd_1894', 'd_1895', 'd_1896', 'd_1897', 'd_1898', 'd_1899',\n",
        "       'd_1900', 'd_1901', 'd_1902', 'd_1903', 'd_1904', 'd_1905', 'd_1906',\n",
        "       'd_1907', 'd_1908', 'd_1909', 'd_1910', 'd_1911', 'd_1912', 'd_1913']].values\n",
        "    predicted=agg[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
        "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
        "       'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28']].values\n",
        "    training=agg[['d_'+str(i) for i in range(1,1886)]].values\n",
        "    weights=agg['weight'].values\n",
        "    rmsse=caluclate_WRMSSE(actual,predicted,training,weights,28,1886)\n",
        "    cv_wrsmme=np.sum(rmsse*weights)\n",
        "    cv.drop(['pred_sales'],axis=1,inplace=True)\n",
        "    del actual,predicted,training,weights,agg\n",
        "    \n",
        "    #For Test data\n",
        "    test['prices']=test['sales']*test['sell_price']\n",
        "    total_sales=test.groupby('id').sum()\n",
        "    total=sum(total_sales['sales'])\n",
        "    weight={}\n",
        "    for i in total_sales.index:\n",
        "        weight[i.replace('evaluation','validation')]=total_sales.loc[i]['sales']/total\n",
        "    test['id']=test['id'].apply(lambda x:x.replace('evaluation','validation'))\n",
        "    train1=pd.concat([train,cv,test])\n",
        "    train1.sort_values(['id','date'],inplace=True)\n",
        "    train1.fillna(0,inplace=True)\n",
        "    df=train1.pivot_table(index=['id','state_id','store_id','cat_id','dept_id','item_id'],columns='d',values='sales')\n",
        "    df.reset_index(level=[0,1,2,3,4,5],inplace=True)\n",
        "    df.fillna(0,inplace=True)\n",
        "    del train1\n",
        "    import gc\n",
        "    test['pred_sales']=model.predict(X_test)\n",
        "    df1=test.pivot_table(index=['id'],columns='d',values='pred_sales')\n",
        "    dic={}\n",
        "    for j,i in enumerate(range(1914,1942)):\n",
        "        dic['d_'+str(i)]='F'+str(j+1)\n",
        "    df1=df1.rename(columns=dic) \n",
        "    df1.reset_index(level=[0],inplace=True)\n",
        "    dd=df.merge(df1,on='id')\n",
        "    dd['weight']=dd['id'].apply(lambda x:weight[x])\n",
        "    l=['d_'+str(i) for i in range(1,1942)]\n",
        "    l1=['F'+str(i) for i in range(1,29)]\n",
        "    agg_level={2:['state_id'],3:['store_id'],4:['cat_id'],5:['dept_id'],6:['state_id','cat_id'],\\\n",
        "           7:['state_id','dept_id'],8:['store_id','cat_id'],9:['store_id','dept_id'],10:['item_id'],11:['item_id','state_id']}\n",
        "    agg=pd.DataFrame(dd[l+l1].sum()).transpose()\n",
        "    agg['weight']=1/12\n",
        "    agg['level']=1\n",
        "    col=agg.columns\n",
        "    for level in agg_level:\n",
        "        temp_df=dd.groupby(by=agg_level[level]).sum().reset_index(drop=True)\n",
        "        temp_df['weight']/=12\n",
        "        temp_df['level']=level\n",
        "        agg=agg.append(temp_df[col])\n",
        "    dd['weight']/=12\n",
        "    dd['level']=12    \n",
        "    agg=agg.append(dd[col])\n",
        "    actual=agg[['d_1914', 'd_1915', 'd_1916', 'd_1917', 'd_1918', 'd_1919',\n",
        "       'd_1920', 'd_1921', 'd_1922', 'd_1923', 'd_1924', 'd_1925',\n",
        "       'd_1926', 'd_1927', 'd_1928', 'd_1929', 'd_1930', 'd_1931',\n",
        "       'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937',\n",
        "       'd_1938', 'd_1939', 'd_1940', 'd_1941']].values\n",
        "    predicted=agg[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
        "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
        "       'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28']].values\n",
        "    training=agg[['d_'+str(i) for i in range(1,1914)]].values\n",
        "    weights=agg['weight'].values\n",
        "    rmsse=caluclate_WRMSSE(actual,predicted,training,weights,28,1914)\n",
        "    test_wrsmme=np.sum(rmsse*weights)\n",
        "\n",
        "    print(\"CV WRMSSE=\",cv_wrsmme)\n",
        "    print(\"Test WRMSSE=\",test_wrsmme)"
      ],
      "metadata": {
        "id": "UKIaPpZZLGPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_performances_for_store_wise_trained_model(train,cv,test,cv_pred,test_pred):\n",
        "    '''This Function is used to get WRMSSE that is used in this Case Study as a Metric For CV and Test Data where model is trained according to store id(Mainly used for Catabosst)'''\n",
        "    #For CV Data\n",
        "    cv['prices']=cv['sales']*cv['sell_price']\n",
        "    total_sales=cv.groupby('id').sum()\n",
        "    total=sum(total_sales['sales'])\n",
        "    weight={}\n",
        "    for i in total_sales.index:\n",
        "        weight[i]=total_sales.loc[i]['sales']/total\n",
        "    train1=pd.concat([train,cv])\n",
        "    train1.sort_values(['id','date'],inplace=True)\n",
        "    train1.fillna(0,inplace=True)\n",
        "    df=train1.pivot_table(index=['id','state_id','store_id','cat_id','dept_id','item_id'],columns='d',values='sales')\n",
        "    df.reset_index(level=[0,1,2,3,4,5],inplace=True)\n",
        "    df.fillna(0,inplace=True)\n",
        "    del train1\n",
        "    import gc\n",
        "    \n",
        "    df1=cv_pred\n",
        "    dd=df.merge(df1,on='id')\n",
        "    dd['weight']=dd['id'].apply(lambda x:weight[x])\n",
        "    l=['d_'+str(i) for i in range(1,1914)]\n",
        "    l1=['F'+str(i) for i in range(1,29)]\n",
        "    agg_level={2:['state_id'],3:['store_id'],4:['cat_id'],5:['dept_id'],6:['state_id','cat_id'],\\\n",
        "           7:['state_id','dept_id'],8:['store_id','cat_id'],9:['store_id','dept_id'],10:['item_id'],11:['item_id','state_id']}\n",
        "    agg=pd.DataFrame(dd[l+l1].sum()).transpose()\n",
        "    agg['weight']=1/12\n",
        "    agg['level']=1\n",
        "    col=agg.columns\n",
        "    for level in agg_level:\n",
        "        temp_df=dd.groupby(by=agg_level[level]).sum().reset_index(drop=True)\n",
        "        temp_df['weight']/=12\n",
        "        temp_df['level']=level\n",
        "        agg=agg.append(temp_df[col])\n",
        "    dd['weight']/=12\n",
        "    dd['level']=12    \n",
        "    agg=agg.append(dd[col])\n",
        "    actual=agg[['d_1886', 'd_1887', 'd_1888', 'd_1889', 'd_1890', 'd_1891', 'd_1892',\n",
        "       'd_1893', 'd_1894', 'd_1895', 'd_1896', 'd_1897', 'd_1898', 'd_1899',\n",
        "       'd_1900', 'd_1901', 'd_1902', 'd_1903', 'd_1904', 'd_1905', 'd_1906',\n",
        "       'd_1907', 'd_1908', 'd_1909', 'd_1910', 'd_1911', 'd_1912', 'd_1913']].values\n",
        "    predicted=agg[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
        "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
        "       'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28']].values\n",
        "    training=agg[['d_'+str(i) for i in range(1,1886)]].values\n",
        "    weights=agg['weight'].values\n",
        "    rmsse=caluclate_WRMSSE(actual,predicted,training,weights,28,1886)\n",
        "    cv_wrsmme=np.sum(rmsse*weights)\n",
        "    del actual,predicted,training,weights,agg\n",
        "    \n",
        "    #For Test data\n",
        "    test['prices']=test['sales']*test['sell_price']\n",
        "    total_sales=test.groupby('id').sum()\n",
        "    total=sum(total_sales['sales'])\n",
        "    weight={}\n",
        "    for i in total_sales.index:\n",
        "        weight[i.replace('evaluation','validation')]=total_sales.loc[i]['sales']/total\n",
        "    test['id']=test['id'].apply(lambda x:x.replace('evaluation','validation'))\n",
        "    train1=pd.concat([train,cv,test])\n",
        "    train1.sort_values(['id','date'],inplace=True)\n",
        "    train1.fillna(0,inplace=True)\n",
        "    df=train1.pivot_table(index=['id','state_id','store_id','cat_id','dept_id','item_id'],columns='d',values='sales')\n",
        "    df.reset_index(level=[0,1,2,3,4,5],inplace=True)\n",
        "    df.fillna(0,inplace=True)\n",
        "    del train1\n",
        "    import gc\n",
        "    df1=test_pred\n",
        "    df1['id']=df1['id'].apply(lambda x:x.replace('evaluation','validation'))\n",
        "    dd=df.merge(df1,on='id')\n",
        "    dd['weight']=dd['id'].apply(lambda x:weight[x])\n",
        "    l=['d_'+str(i) for i in range(1,1942)]\n",
        "    l1=['F'+str(i) for i in range(1,29)]\n",
        "    agg_level={2:['state_id'],3:['store_id'],4:['cat_id'],5:['dept_id'],6:['state_id','cat_id'],\\\n",
        "           7:['state_id','dept_id'],8:['store_id','cat_id'],9:['store_id','dept_id'],10:['item_id'],11:['item_id','state_id']}\n",
        "    agg=pd.DataFrame(dd[l+l1].sum()).transpose()\n",
        "    agg['weight']=1/12\n",
        "    agg['level']=1\n",
        "    col=agg.columns\n",
        "    for level in agg_level:\n",
        "        temp_df=dd.groupby(by=agg_level[level]).sum().reset_index(drop=True)\n",
        "        temp_df['weight']/=12\n",
        "        temp_df['level']=level\n",
        "        agg=agg.append(temp_df[col])\n",
        "    dd['weight']/=12\n",
        "    dd['level']=12    \n",
        "    agg=agg.append(dd[col])\n",
        "    actual=agg[['d_1914', 'd_1915', 'd_1916', 'd_1917', 'd_1918', 'd_1919',\n",
        "       'd_1920', 'd_1921', 'd_1922', 'd_1923', 'd_1924', 'd_1925',\n",
        "       'd_1926', 'd_1927', 'd_1928', 'd_1929', 'd_1930', 'd_1931',\n",
        "       'd_1932', 'd_1933', 'd_1934', 'd_1935', 'd_1936', 'd_1937',\n",
        "       'd_1938', 'd_1939', 'd_1940', 'd_1941']].values\n",
        "    predicted=agg[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
        "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
        "       'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28']].values\n",
        "    training=agg[['d_'+str(i) for i in range(1,1914)]].values\n",
        "    weights=agg['weight'].values\n",
        "    rmsse=caluclate_WRMSSE(actual,predicted,training,weights,28,1914)\n",
        "    test_wrsmme=np.sum(rmsse*weights)\n",
        "\n",
        "    print(\"CV WRMSSE=\",cv_wrsmme)\n",
        "    print(\"Test WRMSSE=\",test_wrsmme)\n",
        "    "
      ],
      "metadata": {
        "id": "1jKlPeKzLItI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "BbUQNpG3LLeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. LSTM "
      ],
      "metadata": {
        "id": "G7xOswaOLNeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "input1=tf.keras.layers.Input(shape=1,name='Item_Id')\n",
        "input2=tf.keras.layers.Input(shape=1,name='Dept_Id')\n",
        "input3=tf.keras.layers.Input(shape=1,name='Cat_Id')\n",
        "input4=tf.keras.layers.Input(shape=1,name='Store_Id')\n",
        "input5=tf.keras.layers.Input(shape=1,name='State_Id')\n",
        "input6=tf.keras.layers.Input(shape=1,name='year')\n",
        "input7=tf.keras.layers.Input(shape=1,name='event_name_1')\n",
        "input8=tf.keras.layers.Input(shape=1,name='event_name_2')\n",
        "input9=tf.keras.layers.Input(shape=1,name='season')\n",
        "input10=tf.keras.layers.Input(shape=(1,23),name='Numerical_features')\n",
        "\n",
        "emb1=tf.keras.layers.Embedding(3050,output_dim=150)(input1)\n",
        "emb2=tf.keras.layers.Embedding(8,output_dim=10)(input2)\n",
        "emb3=tf.keras.layers.Embedding(4,output_dim=10)(input3)\n",
        "emb4=tf.keras.layers.Embedding(11,output_dim=10)(input4)\n",
        "emb5=tf.keras.layers.Embedding(4,output_dim=10)(input5)\n",
        "emb6=tf.keras.layers.Embedding(2017,output_dim=10)(input6)\n",
        "emb7=tf.keras.layers.Embedding(32,output_dim=10)(input7)\n",
        "emb8=tf.keras.layers.Embedding(6,output_dim=10)(input8)\n",
        "emb9=tf.keras.layers.Embedding(5,output_dim=10)(input9)\n",
        "\n",
        "lstm1=tf.keras.layers.LSTM(50)(emb1)\n",
        "lstm2=tf.keras.layers.LSTM(10)(emb2)\n",
        "lstm3=tf.keras.layers.LSTM(10)(emb3)\n",
        "lstm4=tf.keras.layers.LSTM(10)(emb4)\n",
        "lstm5=tf.keras.layers.LSTM(10)(emb5)\n",
        "lstm6=tf.keras.layers.LSTM(10)(emb6)\n",
        "lstm7=tf.keras.layers.LSTM(10)(emb7)\n",
        "lstm8=tf.keras.layers.LSTM(10)(emb8)\n",
        "lstm9=tf.keras.layers.LSTM(10)(emb9)\n",
        "lstm10=tf.keras.layers.LSTM(10)(input10)\n",
        "\n",
        "x1=tf.keras.layers.Flatten()(lstm1)\n",
        "x2=tf.keras.layers.Flatten()(lstm2)\n",
        "x3=tf.keras.layers.Flatten()(lstm3)\n",
        "x4=tf.keras.layers.Flatten()(lstm4)\n",
        "x5=tf.keras.layers.Flatten()(lstm5)\n",
        "x6=tf.keras.layers.Flatten()(lstm6)\n",
        "x7=tf.keras.layers.Flatten()(lstm7)\n",
        "x8=tf.keras.layers.Flatten()(lstm8)\n",
        "x9=tf.keras.layers.Flatten()(lstm9)\n",
        "x10=tf.keras.layers.Flatten()(input10)\n",
        "\n",
        "x=tf.keras.layers.Concatenate()([x1,x2,x3,x4,x5,x6,x7,x8,x9,x10])\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "x1=tf.keras.layers.Dense(256,activation='sigmoid')(x)\n",
        "x2=tf.keras.layers.Dense(128,activation='tanh')(x)\n",
        "x3=tf.keras.layers.Dense(64,activation='relu')(x)\n",
        "x4=tf.keras.layers.Dense(1)(x)\n",
        "model=tf.keras.Model([input1,input2,input3,input4,input5,input6,input7,input8,input9,input10],x)"
      ],
      "metadata": {
        "id": "2T_Zr4z_LL1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "1FPbvWG6LQ5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model,show_shapes=True)"
      ],
      "metadata": {
        "id": "ctGyi1SyLTgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0009),loss='mse')\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0007),loss='mse')"
      ],
      "metadata": {
        "id": "RDnu5sGZLUqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[train['item_id'].values.reshape(-1,1),train['dept_id'].values,train['cat_id'].values.reshape(-1,1),train['store_id'].values.reshape(-1,1),\\\n",
        "             train['state_id'].values.reshape(-1,1),train['year'].values.reshape(-1,1),train['event_name_1'].values.reshape(-1,1),train['event_name_2'].values.reshape(-1,1),\\\n",
        "             train['season'].values.reshape(-1,1),train[[ 'roll_7_shift_28_mean',\n",
        "       'roll_14_shift_28_mean', 'roll_30_shift_28_mean',\n",
        "       'roll_60_shift_28_mean', 'roll_360_shift_28_mean',\n",
        "       'roll_7_shift_28_std', 'roll_14_shift_28_std', 'roll_30_shift_28_std',\n",
        "       'roll_60_shift_28_std', 'roll_360_shift_28_std','sell_price','direct_lag_28', 'direct_lag_35', 'direct_lag_42', 'direct_lag_49',\n",
        "       'direct_lag_56', 'direct_lag_63', 'direct_lag_70', 'direct_lag_77',\n",
        "       'direct_lag_84', 'direct_lag_91', 'direct_lag_98','direct_ewm']].values.reshape(-1,1,23)],\\\n",
        "          y=train['sales'],epochs=15,verbose=1,batch_size=50000,\\\n",
        "          validation_data=([cv['item_id'].values.reshape(-1,1),cv['dept_id'].values,cv['cat_id'].values.reshape(-1,1),cv['store_id'].values.reshape(-1,1),\\\n",
        "             cv['state_id'].values.reshape(-1,1),cv['year'].values.reshape(-1,1),cv['event_name_1'].values.reshape(-1,1),cv['event_name_2'].values.reshape(-1,1),\\\n",
        "             cv['season'].values.reshape(-1,1),cv[[ 'roll_7_shift_28_mean',\n",
        "       'roll_14_shift_28_mean', 'roll_30_shift_28_mean',\n",
        "       'roll_60_shift_28_mean', 'roll_360_shift_28_mean',\n",
        "       'roll_7_shift_28_std', 'roll_14_shift_28_std', 'roll_30_shift_28_std',\n",
        "       'roll_60_shift_28_std', 'roll_360_shift_28_std','sell_price','direct_lag_28', 'direct_lag_35', 'direct_lag_42', 'direct_lag_49',\n",
        "       'direct_lag_56', 'direct_lag_63', 'direct_lag_70', 'direct_lag_77',\n",
        "       'direct_lag_84', 'direct_lag_91', 'direct_lag_98','direct_ewm']].values.reshape(-1,1,23)],cv['sales']),workers=5,use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "MA5IWpbELWQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GridSearch(x_train,y_train,x_CV,y_CV,parameter):\n",
        "\n",
        "  learning_rate=parameter['learning_rate']\n",
        "  n_estimators=parameter['n_estimators']\n",
        "  train_scores =[]\n",
        "  CV_scores =[]\n",
        "  parameter_str=[]\n",
        "  for i in tqdm(n_estimators):\n",
        "    for j in tqdm(learning_rate):\n",
        "      clf=LSTM(objective='poisson' ,learning_rate=j,n_estimators=i)\n",
        "      clf.fit(x_train,y_train)\n",
        "      ## predicting CV data\n",
        "      y_predict=clf.predict(x_CV)\n",
        "      RMSE=mean_squared_error(y_CV, y_predict, squared=False)\n",
        "      CV_scores.append(RMSE)\n",
        "      ## predicting training data\n",
        "      y_predict_=clf.predict(x_train)\n",
        "      RMSE_=mean_squared_error(y_train, y_predict_, squared=False)\n",
        "      train_scores.append(RMSE_)\n",
        "\n",
        "      parameter_str.append('n_est:'+str(i)+'__'+'LR:'+str(j))\n",
        "  return train_scores,CV_scores,parameter_str\n",
        "\n",
        "parameters = {'learning_rate':[0.0001, 0.001, 0.01, 0.1,0.2,10] , 'n_estimators': [10,50,75,100,150] }\n",
        "train_scores,CV_scores,parameter_str=GridSearch(x_train,y_train,x_CV,y_CV,parameters)"
      ],
      "metadata": {
        "id": "RaH8sJMU63CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "get_model_performances(model,train,cv,test,[cv['item_id'].values.reshape(-1,1),cv['dept_id'].values,cv['cat_id'].values.reshape(-1,1),cv['store_id'].values.reshape(-1,1),\\\n",
        "             cv['state_id'].values.reshape(-1,1),cv['year'].values.reshape(-1,1),cv['event_name_1'].values.reshape(-1,1),cv['event_name_2'].values.reshape(-1,1),\\\n",
        "             cv['season'].values.reshape(-1,1),cv[['roll_7_shift_28_mean',\n",
        "       'roll_14_shift_28_mean', 'roll_30_shift_28_mean',\n",
        "       'roll_60_shift_28_mean', 'roll_360_shift_28_mean',\n",
        "       'roll_7_shift_28_std', 'roll_14_shift_28_std', 'roll_30_shift_28_std',\n",
        "       'roll_60_shift_28_std', 'roll_360_shift_28_std','sell_price','direct_lag_28', 'direct_lag_35', 'direct_lag_42', 'direct_lag_49',\n",
        "       'direct_lag_56', 'direct_lag_63', 'direct_lag_70', 'direct_lag_77',\n",
        "       'direct_lag_84', 'direct_lag_91', 'direct_lag_98','direct_ewm']].values.reshape(-1,1,23)],\\\n",
        "                       [test['item_id'].values.reshape(-1,1),test['dept_id'].values,test['cat_id'].values.reshape(-1,1),test['store_id'].values.reshape(-1,1),\\\n",
        "             test['state_id'].values.reshape(-1,1),test['year'].values.reshape(-1,1),test['event_name_1'].values.reshape(-1,1),test['event_name_2'].values.reshape(-1,1),\\\n",
        "             test['season'].values.reshape(-1,1),test[['roll_7_shift_28_mean',\n",
        "       'roll_14_shift_28_mean', 'roll_30_shift_28_mean',\n",
        "       'roll_60_shift_28_mean', 'roll_360_shift_28_mean',\n",
        "       'roll_7_shift_28_std', 'roll_14_shift_28_std', 'roll_30_shift_28_std',\n",
        "       'roll_60_shift_28_std', 'roll_360_shift_28_std','sell_price','direct_lag_28', 'direct_lag_35', 'direct_lag_42', 'direct_lag_49',\n",
        "       'direct_lag_56', 'direct_lag_63', 'direct_lag_70', 'direct_lag_77',\n",
        "       'direct_lag_84', 'direct_lag_91', 'direct_lag_98','direct_ewm']].values.reshape(-1,1,23)])"
      ],
      "metadata": {
        "id": "9i0kQ2v1LYTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting for test data\n",
        "test['pred_sales']=model.predict([test['item_id'].values.reshape(-1,1),test['dept_id'].values,test['cat_id'].values.reshape(-1,1),test['store_id'].values.reshape(-1,1),\\\n",
        "             test['state_id'].values.reshape(-1,1),test['year'].values.reshape(-1,1),test['event_name_1'].values.reshape(-1,1),test['event_name_2'].values.reshape(-1,1),\\\n",
        "             test['season'].values.reshape(-1,1),test[['roll_7_shift_28_mean',\n",
        "       'roll_14_shift_28_mean', 'roll_30_shift_28_mean',\n",
        "       'roll_60_shift_28_mean', 'roll_360_shift_28_mean',\n",
        "       'roll_7_shift_28_std', 'roll_14_shift_28_std', 'roll_30_shift_28_std',\n",
        "       'roll_60_shift_28_std', 'roll_360_shift_28_std','sell_price','direct_lag_28', 'direct_lag_35', 'direct_lag_42', 'direct_lag_49',\n",
        "       'direct_lag_56', 'direct_lag_63', 'direct_lag_70', 'direct_lag_77',\n",
        "       'direct_lag_84', 'direct_lag_91', 'direct_lag_98','direct_ewm']].values.reshape(-1,1,23)])"
      ],
      "metadata": {
        "id": "wm1grHKuLbsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting sales for final_test data\n",
        "final_test['pred_sales']=model.predict([final_test['item_id'].values.reshape(-1,1),test['dept_id'].values,final_test['cat_id'].values.reshape(-1,1),final_test['store_id'].values.reshape(-1,1),\\\n",
        "             final_test['state_id'].values.reshape(-1,1),final_test['year'].values.reshape(-1,1),final_test['event_name_1'].values.reshape(-1,1),final_test['event_name_2'].values.reshape(-1,1),\\\n",
        "             final_test['season'].values.reshape(-1,1),final_test[['roll_7_shift_28_mean',\n",
        "       'roll_14_shift_28_mean', 'roll_30_shift_28_mean',\n",
        "       'roll_60_shift_28_mean', 'roll_360_shift_28_mean',\n",
        "       'roll_7_shift_28_std', 'roll_14_shift_28_std', 'roll_30_shift_28_std',\n",
        "       'roll_60_shift_28_std', 'roll_360_shift_28_std','sell_price','direct_lag_28', 'direct_lag_35', 'direct_lag_42', 'direct_lag_49',\n",
        "       'direct_lag_56', 'direct_lag_63', 'direct_lag_70', 'direct_lag_77',\n",
        "       'direct_lag_84', 'direct_lag_91', 'direct_lag_98','direct_ewm']].values.reshape(-1,1,23)])"
      ],
      "metadata": {
        "id": "fYuDiJxYLWXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df=test.pivot_table(index='id',columns='date',values='pred_sales')\n",
        "df.reset_index(level=0,inplace=True)\n",
        "df['id']=df['id'].apply(lambda x:x.replace('evaluation','validation'))\n",
        "dic={}\n",
        "l=test['date'].unique()\n",
        "for i,day in enumerate(l):\n",
        "    dic[day]='F'+str(i+1)\n",
        "df.rename(columns=dic,inplace=True)    "
      ],
      "metadata": {
        "id": "garFN0LQLhnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df1=final_test.pivot_table(index='id',columns='d',values='pred_sales')\n",
        "df1.reset_index(level=0,inplace=True)\n",
        "dic={}\n",
        "for i,day in enumerate(range(1942,1970)):\n",
        "    dic['d_'+str(day)]='F'+str(i+1)\n",
        "df1.rename(columns=dic,inplace=True)    "
      ],
      "metadata": {
        "id": "KM6va3BLLlsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.concat([df1,df])"
      ],
      "metadata": {
        "id": "nklwWQltLnYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('NN.csv',index=False)"
      ],
      "metadata": {
        "id": "G--84hNGLpqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see how predicted sales varies form actual for FOODS_3_090_CA_3_validation\n",
        "nn=pd.read_csv('NN.csv')\n",
        "test.sort_values(['id','date'],inplace=True)\n",
        "tt=test.pivot_table(index='id',values='sales',columns='d')\n",
        "tt.reset_index(level=0,inplace=True)\n",
        "tt['id']=tt['id'].apply(lambda x:x.replace('evaluation','validation'))\n",
        "actual_sales=tt[tt['id']=='FOODS_3_090_CA_3_validation'].values.flatten()[1:]\n",
        "pred_sales=nn[nn['id']=='FOODS_3_090_CA_3_validation'].values.flatten()[1:]\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(actual_sales,label='Actual Values',marker='o')\n",
        "plt.plot(pred_sales,label='Predicted Sales',marker='o')\n",
        "plt.title(\"Actual Vs Predicted Sales of FOODS_3_090_CA_3_validation by LSTM NN\")\n",
        "plt.ylabel('sales')\n",
        "plt.xlabel('days')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-27pRycqLrjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tw7UAbz60Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARIMA\n"
      ],
      "metadata": {
        "id": "1LypNxBKMgs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyramid.arima import auto_arima\n",
        "stepwise_model = auto_arima(dat, start_p=1, d=1, start_q=1,\n",
        "                           max_p=3, max_q=3, m=12,\n",
        "                           start_P=0, seasonal=True,\n",
        "                           D=1, trace=True,\n",
        "                           error_action='ignore',  \n",
        "                           suppress_warnings=True)\n",
        "print(stepwise_model.aic())"
      ],
      "metadata": {
        "id": "jOTC5xXpMiQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fit ARIMA: order=(1, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=2760.510, BIC=2774.848, Fit time=1.505 seconds\n",
        "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 0, 12); AIC=2842.204, BIC=2847.939, Fit time=0.048 seconds\n",
        "Fit ARIMA: order=(1, 1, 0) seasonal_order=(1, 1, 0, 12); AIC=2806.564, BIC=2818.034, Fit time=0.202 seconds\n",
        "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 1, 12); AIC=2759.891, BIC=2771.361, Fit time=1.477 seconds\n",
        "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 1, 12); AIC=2789.475, BIC=2803.813, Fit time=0.486 seconds\n",
        "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 0, 12); AIC=2842.065, BIC=2850.668, Fit time=0.145 seconds\n",
        "Fit ARIMA: order=(0, 1, 1) seasonal_order=(0, 1, 2, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
        "Fit ARIMA: order=(0, 1, 1) seasonal_order=(1, 1, 2, 12); AIC=2784.482, BIC=2801.687, Fit time=12.198 seconds\n",
        "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=2758.284, BIC=2766.887, Fit time=0.798 seconds\n",
        "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 1, 12); AIC=2760.066, BIC=2771.537, Fit time=1.015 seconds\n",
        "Fit ARIMA: order=(0, 1, 0) seasonal_order=(0, 1, 2, 12); AIC=nan, BIC=nan, Fit time=nan seconds\n",
        "Fit ARIMA: order=(0, 1, 0) seasonal_order=(1, 1, 2, 12); AIC=2790.007, BIC=2804.345, Fit time=4.098 seconds\n",
        "Fit ARIMA: order=(1, 1, 0) seasonal_order=(0, 1, 1, 12); AIC=2760.133, BIC=2771.603, Fit time=1.594 seconds\n",
        "Total fit time: 23.614 seconds\n",
        "2758.2843325496183"
      ],
      "metadata": {
        "id": "Z8XkNwS0Mo0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = dat.loc[:'2012-05-01']\n",
        "test = dat.loc['2012-05-01':]\n",
        "stepwise_model.fit(train)"
      ],
      "metadata": {
        "id": "0P6wNClqMq1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARIMA(callback=None, disp=0, maxiter=50, method=None, order=(0, 1, 0),\n",
        "   out_of_sample_size=0, scoring='mse', scoring_args={},\n",
        "   seasonal_order=(0, 1, 1, 12), solver='lbfgs', start_params=None,\n",
        "   suppress_warnings=True, transparams=True, trend='c')"
      ],
      "metadata": {
        "id": "izdI4wpsMwsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_forecast = stepwise_model.predict(n_periods=len(test))"
      ],
      "metadata": {
        "id": "f_NXCFFuMyyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_forecast = pd.DataFrame(future_forecast,index = test.index,columns=['Prediction'])\n",
        "pd.concat([test,future_forecast],axis=1).plot()"
      ],
      "metadata": {
        "id": "skDFMJ5RM0MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x7f4ffc078490>"
      ],
      "metadata": {
        "id": "Dli60BuDM2Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([dat,future_forecast],axis=1).plot(figsize=(15, 6),\n",
        "                                             title=\"Walmart Sales in One Department of One Store Feb 2010 "
      ],
      "metadata": {
        "id": "dul4GEvPM32v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fd2f3c0d0>"
      ],
      "metadata": {
        "id": "rfQcAhvnM5lN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}